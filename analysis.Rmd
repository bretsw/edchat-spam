---
title: "Spam Project Analysis"
author: "K. Bret Staudt Willet"
date: "6/3/2019"
output: 
    html_document:
        toc: true
        float_toc: true
---

# Get set up

This section loads the data and packages and starts to process the data, but doesn't calculate any statistics or create any results.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
usethis::use_git_ignore(c("*.csv", "*.rds"))
```

## Load packages

```{r, include=FALSE}
library(tidyverse)
library(lubridate)
```

## Load the data

Having completed the steps in the setup.Rmd file, you now have the dataset stored in your local repository and can load it as usual. 

```{r, include=FALSE}
edchat_full <- read.csv("edchat_full_df.csv", 
                        header=TRUE, 
                        colClasses= c(status_id='character',
                                      user_id='character')
                        )
```

# Review the full dataset

```{r, include=TRUE}
n_tweets_full <- edchat_full %>% pull(id_str) %>%
    unique() %>% 
    length()
n_tweeters_full <- edchat_full %>% pull(from_user_id_str) %>%
    unique() %>% 
    length()
paste("Number of unique tweets:", n_tweets_full); paste("Number of unique tweeters:", n_tweeters_full)
```

# Identifying spam in the data

## Clean with rtweet

Our first step of de-spamming our dataset is to run the data through the `rtweet` R package, which queries the Twitter API to return the most complete set of tweet metadata available. See https://rtweet.info/ for details on `rtweet`.

```{r, include=FALSE}
edchat_rtweet <- read.csv("edchat_rtweet_df.csv", 
                          header=TRUE, 
                          colClasses= c(status_id='character',
                                        user_id='character')
                          )
```

```{r, include=TRUE, echo=FALSE}
n_tweets_rtweet <- edchat_rtweet %>% pull(status_id) %>%
    unique() %>% 
    length()
n_tweeters_rtweet <- edchat_rtweet %>% pull(user_id) %>%
    unique() %>% 
    length()
paste("Number of unique tweets after rtweet:", n_tweets_rtweet)
paste("Number of unique tweeters after rtweet:", n_tweeters_rtweet)
```

```{r, include=TRUE, echo=FALSE}
tweet_loss_rtweet <- n_tweets_full - n_tweets_rtweet
tweeter_loss_rtweet <- n_tweeters_full - n_tweeters_rtweet
paste("Tweets lost:", tweet_loss_rtweet, 
      "(", round(100 * tweet_loss_rtweet / n_tweets_full, 2), "% )")
paste("Tweeters lost:", tweeter_loss_rtweet, 
      "(", round(100 * tweeter_loss_rtweet / n_tweeters_full, 2), "% )")
```

```{r, include=TRUE, echo=FALSE}
edchat_rtweet_public <- edchat_rtweet %>% filter(protected=="FALSE")
n_tweets_rtweet_public <- edchat_rtweet_public %>% pull(status_id) %>%
    unique() %>% 
    length()
n_tweeters_rtweet_public <- edchat_rtweet_public %>% pull(user_id) %>%
    unique() %>% 
    length()
paste("Number of public unique tweets after rtweet:", n_tweets_rtweet_public)
paste("Number of public unique tweeters after rtweet:", n_tweeters_rtweet_public)
```

```{r, include=TRUE, echo=FALSE}
tweet_loss_rtweet_public <- n_tweets_rtweet - n_tweets_rtweet_public
tweeter_loss_rtweet_public <- n_tweeters_rtweet - n_tweeters_rtweet_public
tweet_loss_rtweet_public; tweeter_loss_rtweet_public
paste("Tweets lost:", tweet_loss_rtweet_public, 
      "(", round(100 * tweet_loss_rtweet_public / n_tweets_rtweet, 2), "% )")
paste("Tweeters lost:", tweeter_loss_rtweet_public, 
      "(", round(100 * tweeter_loss_rtweet_public / n_tweeters_rtweet, 2), "% )")
```

## Rearrange data and calculate needed measures

```{r, include=FALSE, eval=FALSE}
freq_tweeters <- edchat_rtweet_public %>% 
    pull(user_id) %>% 
    table() %>% 
    as.data.frame() %>% 
    arrange(desc(Freq)) %>%
    rename(tweets_made_edchat = Freq)

pop_mean <- mean(freq_tweeters$tweets_made_edchat)

freq_tweeters <- freq_tweeters %>%
    mutate(sq_mean_diff = (tweets_made_edchat - pop_mean)^2)

pop_sd <- sqrt(mean(freq_tweeters$sq_mean_diff))

freq_tweeters <- freq_tweeters %>%
    mutate(z = (tweets_made_edchat - pop_mean) / pop_sd,
           edchat_prop = (tweets_made_edchat / n_tweets_rtweet_public) * 100
           ) %>%
    select(-sq_mean_diff)
freq_tweeters <- rename(freq_tweeters, user_id = .)
#hist(freq_tweeters$z)
#freq_tweeters %>% head(n=100)
```



```{r, include=FALSE, eval=FALSE}
freq_replies <- edchat_rtweet_public %>% 
    pull(reply_to_status_id) %>% 
    table() %>% 
    as.data.frame() %>% 
    arrange(desc(Freq))
freq_replies <- rename(freq_replies, status_id = ., reply_count = Freq)

edchat_with_replies <- edchat_rtweet_public %>% 
    full_join(freq_replies, by='status_id') %>% 
    mutate(reply_count = ifelse(is.na(reply_count), 0, reply_count)) %>%
    filter(!is.na(user_id))
```

```{r eval=FALSE, include=FALSE}
hashtag_regex <- "#([0-9]|[a-zA-Z])+"
url_regex <- "http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+"

edchat_tweeters <- edchat_with_replies %>% 
    rename(profile_description = description) %>% 
    mutate(tweets_made_all = statuses_count %>% as.numeric(),
           tweets_liked_all = favourites_count %>% as.numeric(),
           favorite_count = favorite_count %>% as.numeric(),
           retweet_count = ifelse(is_retweet=="FALSE",
                                  retweet_count %>% as.numeric(),
                                  NA),
           hashtag_count = str_count(text, hashtag_regex),
               # ifelse(is.na(hashtags), 0, strsplit(hashtags, " ") %>% sapply(length)),
           hashtag_inclusion = ifelse(hashtag_count==0, 0, 1) %>% as.numeric(),
           url_count = str_count(text, url_regex),
               # ifelse(is.na(urls_url), 0, strsplit(urls_url, " ") %>% sapply(length)),
           url_inclusion = ifelse(url_count==0, 0, 1) %>% as.numeric(),
           following_ratio = as.numeric(friends_count) / as.numeric(followers_count)
           ) %>%
    group_by(user_id) %>%
    mutate(like_mean = mean(favorite_count),
           retweet_mean = retweet_count[!is.na(retweet_count)] %>% mean(),
           reply_mean = mean(reply_count),
           hashtag_total = sum(hashtag_count),
           hashtag_mean = mean(hashtag_count),
           url_total = sum(url_count),
           url_mean = mean(url_count),
           tweets_with_hashtags = (sum(hashtag_inclusion) / n()) * 100,
           tweets_with_url = (sum(url_inclusion) / n()) * 100
              ) %>%
    slice(1) %>%
    full_join(freq_tweeters, by='user_id') %>%
    select(user_id, screen_name,
           tweets_made_all, tweets_made_edchat,
           z, edchat_prop,
           like_mean, retweet_mean, reply_mean,
           following_ratio, friends_count, followers_count,
           hashtag_total, hashtag_mean, tweets_with_hashtags, 
           url_total, url_mean, tweets_with_url,
           tweets_liked_all,
           source, verified,
           profile_description, profile_url
           ) %>%
    arrange(desc(z))

write.csv(edchat_tweeters, "edchat_tweeters.csv", row.names=FALSE)
```

```{r, include=FALSE}
edchat_tweeters <- read.csv("edchat_tweeters.csv", 
                            header=TRUE, 
                            colClasses= c(status_id='character',
                                          user_id='character')
                            )
```

## Apply practical metrics for educational research

*Metric 1. Volume of tweeting*: One indicator of spam is unusually high-volume tweeting as such tweeting is often-bot generated. Related practical indicators of spam include counts of the raw number of tweets, the percentage of tweets to a hashtag accounted for by a user, or more standardized metrics such as z-scores of tweets per user.

```{r, include=TRUE, echo=FALSE}
# Total tweets by tweeter
#edchat_tweeters %>% arrange(desc(tweets_made_all)) %>% head(100) 

# Percentage of #Edchat volume by tweeter
#edchat_tweeters %>% arrange(desc(edchat_prop)) %>% head(100)

# Standard deviations away from the mean  (z-scores)
edchat_mean_tweets <- edchat_tweeters$tweets_made_edchat %>% mean() %>% round(2)
edchat_sd_tweets <- edchat_tweeters$tweets_made_edchat %>% sd() %>% round(2)
edchat_median_tweets <- edchat_tweeters$tweets_made_edchat %>% median()
paste("Mean:", edchat_mean_tweets); paste("SD:", edchat_sd_tweets); paste("Median:", edchat_median_tweets)

edchat_one_timers_n <- edchat_tweeters %>% filter(tweets_made_edchat==1) %>% nrow()
edchat_one_timers_p <- round(100 * edchat_one_timers_n / nrow(edchat_tweeters), 2)
paste("One-time tweeters:", edchat_one_timers_n, "(", edchat_one_timers_p, "% )")

#hist(edchat_tweeters$z, breaks=100, ylim=c(0,50))
```

*Metric 2. Level of interaction*: Because spammers tend to broadcast messages, which others frequently ignore (Lin & Huang, 2013), spam accounts can also be identified by the absence of interaction with others. Relatively easy metrics researchers can use to measure interaction is to examine the extent to which a usersâ€™ tweets result in likes, retweets, and replies.

```{r, include=TRUE, echo=FALSE}
edchat_sorted_by_likes <- edchat_tweeters %>% 
    arrange(desc(like_mean), retweet_mean, reply_mean, z) %>%
    select(user_id, screen_name, z, like_mean, retweet_mean, reply_mean)
#View(edchat_sorted_by_likes)

edchat_sorted_by_retweets <- edchat_tweeters %>% 
    arrange(desc(retweet_mean), like_mean, reply_mean, z) %>%
    select(user_id, screen_name, z, like_mean, retweet_mean, reply_mean)
#View(edchat_sorted_by_retweets)

edchat_sorted_by_replies <- edchat_tweeters %>% 
    arrange(desc(reply_mean), like_mean, retweet_mean, z) %>%
    select(user_id, screen_name, z, like_mean, retweet_mean, reply_mean)
#View(edchat_sorted_by_replies)
```

*Metric 3. Following vs. followers*: Spammers often follow many other users, but themselves have relatively low number of followers. Researchers can quickly measure this phenomenon by calculating the ratio of following to followers for users in their dataset.

```{r, include=TRUE, echo=FALSE}
edchat_no_followers_n <- edchat_tweeters %>% filter(following_ratio==Inf) %>% nrow()
edchat_no_followers_p <- round(100 * edchat_no_followers_n / nrow(edchat_tweeters), 2)
paste("Tweeters with no followers:", edchat_no_followers_n, "(", edchat_no_followers_p, "% )")

edchat_sorted_by_following_ratio <- edchat_tweeters %>% 
    arrange(desc(following_ratio), desc(z)) %>%
    select(user_id, screen_name, z, following_ratio, friends_count, followers_count, 
           like_mean, retweet_mean, reply_mean)
#View(edchat_sorted_by_following_ratio)
```

*Metric 4. Level of hyperlinking*: Many spammers share hyperlinks in an attempt to drive traffic to certain websites (e.g., Lin & Huang, 2013) For instance, a tweet might advertise goods for sale and include a hyperlink to the website where the actual purchase would occur. Researchers can therefore analyze the raw number of links, the percentage of tweets that contain a link, or the average number of links per tweet.

```{r, include=TRUE, echo=FALSE}
edchat_sorted_by_hashtags <- edchat_tweeters %>% 
    arrange(desc(tweets_with_hashtags)) %>%
    select(user_id, screen_name, z, 
           tweets_made_all, tweets_made_edchat,
           hashtag_total, hashtag_mean, tweets_with_hashtags, 
           url_total, url_mean, tweets_with_url)
#View(edchat_sorted_by_hashtags)

edchat_sorted_by_urls <- edchat_tweeters %>% 
    arrange(desc(url_mean)) %>%
    select(user_id, screen_name, z, 
           tweets_made_all, tweets_made_edchat,
           hashtag_total, hashtag_mean, tweets_with_hashtags, 
           url_total, url_mean, tweets_with_url)
#View(edchat_sorted_by_urls)
```

# Making decisions about what to do with the spammers

## Case A: Consider top-10 tweeters and decide who to exclude

For comparison between #Edchat and other hashtags, need to remove most prolific, bot-like contributors. We took a holistic approach to applying our practical metrics for spam detection. We first looked at the volume of tweets contributed to #Edchat, then looked at the contributors' profile descriptions. Third, we knew these accounts were active and not suspended because `rtweet` was able to pull their information. Fourth, considering the proportion of #Edchat tweets contributed by the top-10 users was not particularly useful, because the overall volume of #Edchat is so large. Fifth, we looked at interaction measures such as mean retweets, likes, and replies per per tweet. Sixth, we looked at the percentage of tweets  containing hyperlinks. Seventh, we used Kearney's TweetBotOrNot tool (https://mikewk.shinyapps.io/botornot/) to find the "estimated probability of user being an automated account." Eighth, we looked at the content of each user's tweets.

```{r, include=TRUE, echo=FALSE}
edchat_exclude <- edchat_tweeters %>% 
    arrange(desc(z)) %>%
    head(10) %>%
    select(user_id, screen_name, tweets_made_all, tweets_made_edchat, 
           z, edchat_prop, 
           retweet_mean, like_mean, reply_mean,
           tweets_with_url, url_mean, hashtag_mean,
           profile_description, profile_url
           )
edchat_exclude$botornot <- c(.320,
                             .080,
                             .406,
                             .011,
                             .008,
                             .285,
                             .721,
                             .002,
                             .057,
                             .010
                            )
edchat_exclude$spammer <- c("yes", 
                            "yes", 
                            "yes", 
                            "no", 
                            "yes (discuss)", 
                            "no (discuss)", 
                            "yes", 
                            "no (discuss)", 
                            "yes", 
                            "yes"
                            )
#View(edchat_exclude)

exclude_filter <- edchat_exclude %>% 
    #filter(grepl("yes*", spammer)) %>%
    pull(screen_name) %>% 
    as.character()

edchat_unspammed <- edchat_rtweet_public %>% filter(!(screen_name %in% exclude_filter))
n_tweets_unspammed <- edchat_unspammed %>% 
    pull(status_id) %>%
    unique() %>% 
    length()
n_tweeters_unspammed <- edchat_unspammed %>% 
    pull(user_id) %>%
    unique() %>% 
    length()
paste("Number of public unique tweets after removing spammers:", n_tweets_unspammed)
paste("Number of public unique tweeters after removing spammers:", n_tweeters_unspammed)
```

For comparison to other Twitter education hashtags, look at tweets (original tweets only, not retweets) per month per user.

```{r, include=TRUE, echo=FALSE}
time_start_rtweet <- edchat_rtweet_public$created_at %>% as.character() %>% min() %>% ymd_hms()
time_end_rtweet <- edchat_rtweet_public$created_at %>% as.character() %>% max() %>% ymd_hms()
n_months_rtweet <- (time_end_rtweet - time_start_rtweet) %>% time_length(unit="months")

time_start_unspammed <- edchat_unspammed$created_at %>% as.character() %>% min() %>% ymd_hms()
time_end_unspammed <- edchat_unspammed$created_at %>% as.character() %>% max() %>% ymd_hms()
n_months_unspammed <- (time_end_unspammed - time_start_unspammed) %>% time_length(unit="months")

n_orig_tweets <- edchat_rtweet_public %>% 
    filter(is_retweet == FALSE) %>% 
    pull(status_id) %>%
    unique() %>% 
    length()
    
n_orig_tweeters <- edchat_rtweet_public %>% 
    filter(is_retweet == FALSE) %>% 
    pull(user_id) %>%
    unique() %>% 
    length()
paste("Number of original tweets:", n_orig_tweets); paste("Number of orginal tweeters:", n_orig_tweeters)

n_orig_tweets_unspammed <- edchat_unspammed %>% 
    filter(is_retweet == FALSE) %>% 
    pull(status_id) %>%
    unique() %>% 
    length()
    
n_orig_tweeters_unspammed <- edchat_unspammed %>% 
    filter(is_retweet == FALSE) %>% 
    pull(user_id) %>%
    unique() %>% 
    length()
paste("Number of original tweets minus spam:", 
      n_orig_tweets_unspammed); paste("Number of original tweeters minus spam:", 
                            n_orig_tweeters_unspammed)

paste("Tweets per month per user:", 
      round(n_orig_tweets / n_months_rtweet / n_orig_tweeters, 2)
      )
paste("Tweets per month per user after removing spammers:", 
      round(n_orig_tweets_unspammed / n_months_unspammed / n_orig_tweeters_unspammed, 2)
      )
```

```{r, include=TRUE, echo=FALSE}
tweeter_loss_unspammed <- n_tweeters_rtweet_public - n_tweeters_unspammed
tweet_loss_unspammed <- n_tweets_rtweet_public - n_tweets_unspammed

paste("Tweeters lost after removing spammers:", tweeter_loss_unspammed, 
      "(", round(100 * tweeter_loss_unspammed / n_tweeters_rtweet_public, 2), "% )")
paste("Tweets lost after removing spammers:", tweet_loss_unspammed, 
      "(", round(100 * tweet_loss_unspammed / n_tweets_rtweet_public, 2), "% )")
```

## Case B: Consider low-interaction tweeters and decide who to highlight

To study potential self-promotional behavior within #Edchat, need to identify and focus upon contributors who exhibit certain markers.

Archetype of self-promotional behaviors... Combo of markers
Inclusion of many hashtags (how many including if hoping to engage in dialogue? 2 or 3?) 4, 7, 10... 

Started by talking about different types of spammers, are realizing that we can identify different types of user archetypes, not just the type of users we want to remove from the dataset. See Prestridge (2019) in *Computers & Education* that offers suggestions for types of users.

```{r, include=TRUE}
edchat_focus <- edchat_tweeters %>% 
    filter(!is.nan(retweet_mean),
           z > 2,
           following_ratio > 2, 
           like_mean < 1,
           retweet_mean < 1,
           reply_mean < 1
           )
nrow(edchat_focus) # 29 (this increases to 103 tweeters if looking at following_ratio > 1)
#View(edchat_focus)

edchat_tweeters %>% filter(following_ratio > 10) %>% nrow()  #2588
edchat_tweeters %>% filter(url_mean > 2) %>% nrow()  # 610

edchat_tweeters %>% filter(!is.nan(retweet_mean), hashtag_mean > 4) %>% nrow()  # 7,897
edchat_tweeters %>% filter(!is.nan(retweet_mean), hashtag_mean > 5) %>% nrow()  # 4,454
edchat_tweeters %>% filter(!is.nan(retweet_mean), hashtag_mean > 6) %>% nrow()  # 2,581
edchat_tweeters %>% filter(!is.nan(retweet_mean), hashtag_mean > 7) %>% nrow()  # 1,675
edchat_tweeters %>% filter(!is.nan(retweet_mean), hashtag_mean > 8) %>% nrow()  # 1,126
edchat_tweeters %>% filter(!is.nan(retweet_mean), hashtag_mean > 9) %>% nrow()  # 770
edchat_tweeters %>% filter(!is.nan(retweet_mean), hashtag_mean > 10) %>% nrow()  # 568
```
